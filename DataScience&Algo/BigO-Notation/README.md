Big O Notation is the language computer scientists use when comparing the performance of algorithims. It's all about dominant operations
  time (how fast)
  space (how much memory)

There's typically a linear relationship between the amount of elements in an algorithim and its runtime, although it is not perfectly linear because computers are so fast now. 

Linear time is referred to as 0(n) and is present wherever there is a loop, where n is the time complexity based on the length of the object.

Constant Time, where the algorithm does a calculation and returns a value, this notation is 0(1) (extremely quick)

Logaithmic Time, the algorithm loops and cuts the value in half each time (binary search tree)

Quadratic Time, the algorithm time doubles because of two for loops, with one embedded in eachother.
